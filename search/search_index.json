{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Quick Start","text":""},{"location":"#getting-started-with-deepstream-101","title":"Getting Started with deepstream-101","text":"<p>New developers often find it challenging to set up the environment and run DeepStream Python applications. This page is intended for beginners seeking a deep understanding of the <code>NVIDIA DeepStream SDK</code>. If you are a developer who wants contribute to the project, please visit the development page.</p>"},{"location":"#installation","title":"Installation","text":"<p>Visit this guide</p>"},{"location":"#sample-applications","title":"Sample Applications","text":"<p>The sample applications included in this repository demonstrate how to build and manage DeepStream pipelines using Python.</p> <p>For detailed examples, please refer to the DeepStream Python Apps.</p>"},{"location":"#feedback","title":"Feedback","text":"<p>Feel free to create a bug report or a feature request on our repo</p>"},{"location":"install/","title":"Install","text":""},{"location":"install/#supported-platforms","title":"Supported Platforms","text":"<p>This release supports Ubuntu 20.04 for DeepStream SDK 6.3 with Python 3.8. Other versions may require adjustments. The recommended setup is Docker-based for both dGPUs and Jetson platforms, though a base environment can also be used.</p>"},{"location":"install/#installation","title":"Installation","text":"<ol> <li> <p>Pull the DeepStream Docker container</p> <p>Run the following command to download the official NVIDIA DeepStream container:   </p><pre><code>docker pull nvcr.io/nvidia/deepstream:6.3-triton-multiarch\n</code></pre> </li> <li> <p>Clone the repository</p> <pre><code>git clone https://github.com/quangdungluong/deepstream-101\ncd deepstream-101\n</code></pre> </li> <li> <p>Run the docker container     Start a DeepStream container with necessary permissions and volume mounting     </p><pre><code>docker run \\\n    -it --rm \\\n    --runtime nvidia \\\n    --device /dev/snd \\\n    -v ./apps:/apps \\\n    -w /apps \\\n    --name deepstream-101 \\\n    -p 8554:8554 \\\n    nvcr.io/nvidia/deepstream:6.3-triton-multiarch\n</code></pre> </li> <li> <p>Install necessary libraries</p> <p>Inside the container, install the Python bindings for DeepStream   </p><pre><code># Download and install pyds\nwget https://github.com/NVIDIA-AI-IOT/deepstream_python_apps/releases/download/v1.1.8/pyds-1.1.8-py3-none-linux_x86_64.whl\npip3 install pyds-1.1.8-py3-none-linux_x86_64.whl\n# Install cuda-python\npip3 install cuda-python\n</code></pre> </li> <li> <p>Setup complete - Start exploring DeepStream in Python</p> <p>You're now ready to dive into DeepStream Python applications.\ud83d\ude80   Let me know if you need any modifications.</p> </li> </ol>"},{"location":"apps/deepstream-rt-src-add-del/","title":"Deepstream rt src add del","text":"<pre><code>python3 deepstream_rt_src_add_del.py file:///opt/nvidia/deepstream/deepstream-6.3/samples/streams/sample_1080p_h264.mp4\n</code></pre>"},{"location":"apps/deepstream-rtsp-in-rtsp-out/","title":"Deepstream rtsp in rtsp out","text":""},{"location":"apps/deepstream-rtsp-in-rtsp-out/#download-model","title":"Download model","text":"<pre><code>export MODEL_REPO_DIR=/apps/models\nmkdir -p ${MODEL_REPO_DIR}/ssd_inception_v2_coco_2018_01_28/1\nwget -O /tmp/ssd_inception_v2_coco_2018_01_28.tar.gz \\\n     http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz\ncd /tmp &amp;&amp; tar xzf ssd_inception_v2_coco_2018_01_28.tar.gz\nmv /tmp/ssd_inception_v2_coco_2018_01_28/frozen_inference_graph.pb \\\n    ${MODEL_REPO_DIR}/ssd_inception_v2_coco_2018_01_28/1/model.graphdef\nrm -fr /tmp/ssd_inception_v2_coco_2018_01_28.tar.gz  /tmp/ssd_inception_v2_coco_2018_01_28\n</code></pre> <pre><code>cd deepstream-rtsp-in-rtsp-out\n\npython3 deepstream_test1_rtsp_in_rtsp_out.py -i file:///opt/nvidia/deepstream/deepstream-6.3/samples/streams/sample_1080p_h264.mp4\n\n# or\n\npython3 deepstream_test1_rtsp_in_rtsp_out.py -i file:///opt/nvidia/deepstream/deepstream-6.3/samples/streams/sample_1080p_h264.mp4 \\\n        -g nvinferserver\n</code></pre>"},{"location":"apps/deepstream-test1/","title":"deepstream-test1","text":""},{"location":"apps/deepstream-test1/#deepstream-test-1","title":"Deepstream Test 1","text":"<p>The <code>deepstream-test1</code> application shows how to use NVIDIA DeepStream SDK elements in a pipeline and extract meaningful insights from a video stream. This sample creates an instance of the <code>nvinfer</code> element, which uses the TensorRT API to perform inference on a model. It is crucial to configure the <code>nvinfer</code> element correctly, as many of its behaviors are parameterized through configuration files.</p>"},{"location":"apps/deepstream-test1/#preparing-the-model","title":"Preparing the model","text":"<p>This sample uses the TrafficCamNet model, which detects 4 classes: <code>Vehicle</code>, <code>Road Sign</code>, <code>Two-Wheeler</code> and <code>Person</code>. The configuration file used for this detector is <code>dstest1_pgie_config.txt</code>.</p>"},{"location":"apps/deepstream-test1/#downloading-the-model","title":"Downloading the model","text":"<p>To use the model, download it from NGC Models using the following commands: </p><pre><code>wget --content-disposition 'https://api.ngc.nvidia.com/v2/models/org/nvidia/team/tao/trafficcamnet/pruned_onnx_v1.0.3/files?redirect=true&amp;path=resnet18_trafficcamnet_pruned.onnx' -O models/Primary_Detector/resnet18_trafficcamnet_pruned.onnx\nwget --content-disposition 'https://api.ngc.nvidia.com/v2/models/org/nvidia/team/tao/trafficcamnet/pruned_onnx_v1.0.3/files?redirect=true&amp;path=resnet18_trafficcamnet_pruned_int8.txt' -O models/Primary_Detector/resnet18_trafficcamnet_pruned_int8.txt\n</code></pre>"},{"location":"apps/deepstream-test1/#running-the-application","title":"Running the application","text":"<p>The application will automatically export the model into an INT8 engine before execution. </p><pre><code>cd deepstream-test1\n# Run the test application with an H.264 elementary stream\npython3 deepstream_test_1.py /opt/nvidia/deepstream/deepstream/samples/streams/sample_720p.h264\n</code></pre>"},{"location":"apps/deepstream-test2/","title":"deepstream-test2","text":""},{"location":"apps/deepstream-test2/#deepstream-test-2","title":"Deepstream Test 2","text":"<p>This guide explains how to set up and run the <code>deepstream-test2</code> application, which demonstrates object detection and tracking using NVIDIA DeepStream. It leverages <code>nvinfer</code> as the primary inference engine (pgie) and <code>nvtracker</code> for object tracking. Additionally, two secondary inference engines (sgies) classify detected objects.</p>"},{"location":"apps/deepstream-test2/#preparing-the-model","title":"Preparing the model","text":"<p>This sample application uses the following pre-trained models from NVIDIA\u2019s NGC catalog:</p> <ul> <li>TrafficCamNet model, which detects 4 classes: <code>Vehicle</code>, <code>Road Sign</code>, <code>Two-Wheeler</code> and <code>Person</code>. The configuration file used for this detector is <code>dstest2_pgie_config.txt</code>.</li> </ul> <ul> <li>VehicleMakeNet model, which classifies car makes in images. The configuration file uses for this classifier is <code>dstest2_sgie1_config.txt</code>.</li> </ul> <ul> <li>VehicleTypeNet model, which classifies vehicle types. The configuration file uses for this classifier is <code>dstest2_sgie2_config.txt</code>.</li> </ul>"},{"location":"apps/deepstream-test2/#downloading-the-model","title":"Downloading the model","text":"<p>Before running the application, you need to download the required models.</p>"},{"location":"apps/deepstream-test2/#download-trafficcam-model-label","title":"Download TrafficCam model &amp; label","text":"<p>Follow the instruction in deepstream-test1</p>"},{"location":"apps/deepstream-test2/#download-vehiclemake-model-label","title":"Download VehicleMake model &amp; label","text":"<p>To use the model, download it from NGC Models using the following commands: </p><pre><code>wget --content-disposition 'https://api.ngc.nvidia.com/v2/models/org/nvidia/team/tao/vehiclemakenet/pruned_onnx_v1.1.0/files?redirect=true&amp;path=resnet18_pruned.onnx' -O models/Secondary_VehicleMake/resnet18_vehiclemakenet_pruned.onnx\n\nwget --content-disposition 'https://api.ngc.nvidia.com/v2/models/org/nvidia/team/tao/vehiclemakenet/pruned_onnx_v1.1.0/files?redirect=true&amp;path=labels.txt' -O models/Secondary_VehicleMake/labels.txt\n</code></pre>"},{"location":"apps/deepstream-test2/#download-vehicletype-model-label","title":"Download VehicleType model &amp; label","text":"<p>To use the model, download it from NGC Models using the following commands: </p><pre><code>wget --content-disposition 'https://api.ngc.nvidia.com/v2/models/org/nvidia/team/tao/vehicletypenet/pruned_onnx_v1.1.0/files?redirect=true&amp;path=resnet18_pruned.onnx' -O models/Secondary_VehicleTypes/resnet18_vehicletypenet_pruned.onnx\n\nwget --content-disposition 'https://api.ngc.nvidia.com/v2/models/org/nvidia/team/tao/vehicletypenet/pruned_onnx_v1.1.0/files?redirect=true&amp;path=labels.txt' -O models/Secondary_VehicleTypes/labels.txt\n</code></pre>"},{"location":"apps/deepstream-test2/#running-the-application","title":"Running the application","text":"<p>The application will automatically export the model into an INT8 engine before execution. </p><pre><code>cd deepstream-test2\n# Run the test application with an H.264 elementary stream\npython3 deepstream_test_2.py /opt/nvidia/deepstream/deepstream-6.3/samples/streams/sample_720p.h264\n</code></pre> <p>This guide ensures a smooth setup and execution of the DeepStream Test 2 application. \ud83d\ude80</p>"},{"location":"apps/deepstream-test3/","title":"Deepstream test3","text":"<pre><code>wget --content-disposition 'https://api.ngc.nvidia.com/v2/models/org/nvidia/team/tao/peoplenet/deployable_quantized_v2.6/files?redirect=true&amp;path=resnet34_peoplenet_int8.etlt' -O models/tao_pretrained_models/peopleNet/resnet34_peoplenet_int8.etlt\n\nwget --content-disposition 'https://api.ngc.nvidia.com/v2/models/org/nvidia/team/tao/peoplenet/deployable_quantized_v2.6/files?redirect=true&amp;path=resnet34_peoplenet_int8.txt' -O models/tao_pretrained_models/peopleNet/resnet34_peoplenet_int8.txt\n</code></pre> <p>Run </p><pre><code>python3 deepstream_test_3.py -i file:///opt/nvidia/deepstream/deepstream-6.3/samples/streams/sample_1080p_h264.mp4 \\\n        -c config_infer_primary_peoplenet.txt \\\n        -g nvinfer \\\n        --no-display \n\npython3 deepstream_test_3.py -i file:///opt/nvidia/deepstream/deepstream-6.3/samples/streams/sample_1080p_h264.mp4 \\\n        -c config_triton_infer_primary_peoplenet.txt \\\n        -g nvinferserver \\\n        --no-display \n\npython3 deepstream_test_3.py -i file:///opt/nvidia/deepstream/deepstream-6.3/samples/streams/sample_1080p_h264.mp4 \\\n        -c config_triton_infer_primary_peoplenet.txt \\\n        -g nvinferserver-grpc \\\n        --no-display \n</code></pre>"}]}